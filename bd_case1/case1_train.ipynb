{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n",
      "Limiting cpu threads to: 16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from case1_datagen import generate_collocation_points, generate_interface_collocation_points\n",
    "from case1_loss_fns import pde_loss, bc_loss, flexural_rigidity, normalise, denormalise\n",
    "from case1_beamdoublenet import BeamDoubleNet\n",
    "from case1_bayesian_opt import run_bayesian_optimisation\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    torch.set_num_threads(16)\n",
    "    print(f\"Limiting cpu threads to: {torch.get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points generated: 10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'q0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal points generated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x_pde_torch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# The 'data' dictionary is now correct\u001b[39;00m\n\u001b[32m     34\u001b[39m data = {\n\u001b[32m     35\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mx_pde\u001b[39m\u001b[33m'\u001b[39m: x_pde_torch, \u001b[38;5;66;03m# This is now a normalized tensor\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mxmin\u001b[39m\u001b[33m'\u001b[39m: xmin,\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mxmax\u001b[39m\u001b[33m'\u001b[39m: xmax,\n\u001b[32m     38\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m: device,\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mq0\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mq0\u001b[49m,\n\u001b[32m     40\u001b[39m }\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# --- VISUALISATION FIX ---\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Correct way to convert a tensor to a numpy array for plotting\u001b[39;00m\n\u001b[32m     45\u001b[39m x_plot_numpy = x_pde_torch.cpu().detach().numpy().flatten()\n",
      "\u001b[31mNameError\u001b[39m: name 'q0' is not defined"
     ]
    }
   ],
   "source": [
    "# data generation with more collocation points for higher x\n",
    "\n",
    "# --- 1. Define parameters ---\n",
    "n_first_half = 2000\n",
    "n_second_half = 8000\n",
    "split_point = 1.5\n",
    "\n",
    "xmin, xmax = 0.0, 3.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# --- 2. Generate PHYSICAL points and combine them ---\n",
    "points_first = generate_collocation_points(n_first_half, [(xmin, split_point)])[0]\n",
    "points_second = generate_collocation_points(n_second_half, [(split_point, xmax)])[0]\n",
    "x_phys_pde = np.vstack((points_first, points_second)) # This is in the [0, 3] range\n",
    "\n",
    "\n",
    "# --- 3. FIX: Normalize the physical points to the [0, 1] range ---\n",
    "x_norm_pde = normalise(x_phys_pde, xmin, xmax)\n",
    "\n",
    "\n",
    "# --- 4. FIX: Convert to PyTorch Tensor and move to device ---\n",
    "x_pde_torch = torch.from_numpy(x_norm_pde).to(torch.float32).to(device)\n",
    "\n",
    "\n",
    "# --- 5. Shuffle the final TENSOR ---\n",
    "shuffled_indices = torch.randperm(len(x_pde_torch))\n",
    "x_pde_torch = x_pde_torch[shuffled_indices]\n",
    "\n",
    "\n",
    "print(f\"Total points generated: {len(x_pde_torch)}\")\n",
    "\n",
    "\n",
    "# The 'data' dictionary is now correct\n",
    "data = {\n",
    "    'x_pde': x_pde_torch, # This is now a normalized tensor\n",
    "    'xmin': xmin,\n",
    "    'xmax': xmax,\n",
    "    'device': device,\n",
    "    'q0': q0,\n",
    "}\n",
    "\n",
    "\n",
    "# --- VISUALISATION FIX ---\n",
    "# Correct way to convert a tensor to a numpy array for plotting\n",
    "x_plot_numpy = x_pde_torch.cpu().detach().numpy().flatten()\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.scatter(x_plot_numpy, np.zeros_like(x_plot_numpy), alpha=0.5, label='Single Beam PDE points (normalized)')\n",
    "plt.xlabel('Normalized x')\n",
    "plt.yticks([])\n",
    "plt.title('Collocation Points Along Single Beam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDE points for the single beam: 3000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal PDE points for the single beam: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x_pde_torch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# --- VISUALISATION (Simplified) ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m x_pde_combined_flat = \u001b[43mx_pde_torch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m().numpy().flatten() \u001b[38;5;66;03m# Get flat array for plotting\u001b[39;00m\n\u001b[32m     51\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m     52\u001b[39m plt.scatter(x_pde_combined_flat, np.zeros_like(x_pde_combined_flat), alpha=\u001b[32m0.5\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mSingle Beam PDE points (normalized)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'builtin_function_or_method' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the following functions are defined elsewhere:\n",
    "# def generate_collocation_points(n, x_ranges): ...\n",
    "# def normalise(x, xmin, xmax): ...\n",
    "# def generate_interface_collocation_points(n, n_interface, x_ranges, interface_x, interface_width): ...\n",
    "\n",
    "\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# --- Your Data Generation Parameters ---\n",
    "n_collocation = 3000\n",
    "#n_interface = 1000\n",
    "#x_ranges = [(0,2), (2,3)]\n",
    "#interface_x = 2.0\n",
    "#interface_width = 0.1\n",
    "xmin, xmax = 0.0, 3.0\n",
    "q0 = 500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#Generate Uniform Collocation Points for Each Domain\n",
    "x_phys_pde = np.random.uniform(xmin, xmax, (n_collocation, 1)).astype(np.float32)\n",
    "\n",
    "# Normalize the points\n",
    "x_pde_torch = torch.from_numpy(normalise(x_phys_pde, xmin, xmax)).to(torch.float32).to(device)\n",
    "\n",
    "shuffled_indices = torch.randperm(len(x_pde_torch))\n",
    "x_pde_torch = x_pde_torch[shuffled_indices]\n",
    "x_pde_torch.requires_grad_(True)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'x_pde': x_pde_torch,  # Single tensor for all PDE points\n",
    "    'xmin': xmin,\n",
    "    'xmax': xmax,\n",
    "    'device': device,\n",
    "    'q0': q0,\n",
    "}\n",
    "\n",
    "print(f\"Total PDE points for the single beam: {len(x_pde_torch)}\")\n",
    "\n",
    "\n",
    "# --- VISUALISATION (Simplified) ---\n",
    "x_pde_combined_flat = x_pde_torch.cpu.detach().numpy().flatten() # Get flat array for plotting\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.scatter(x_pde_combined_flat, np.zeros_like(x_pde_combined_flat), alpha=0.5, label='Single Beam PDE points (normalized)')\n",
    "# No interface line needed for a single beam\n",
    "plt.xlabel('Normalized x')\n",
    "plt.yticks([])\n",
    "plt.title('Collocation Points Along Single Beam')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian search for the optimal parameters\n",
    "\n",
    "#epochs_per_trial = 300  # A small number of epochs for the search\n",
    "#n_trials = 50           # A reasonable number of trials\n",
    "\n",
    "#print(\"\\n--- Starting Bayesian Optimization Search ---\")\n",
    "#best_params = run_bayesian_optimisation(data, epochs_per_trial, n_trials, device)\n",
    "#print(\"\\n--- Search Complete. Best Parameters Found ---\")\n",
    "#print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "\n",
    "n_units=40\n",
    "n_layers=4\n",
    "pde_weight = 10000.0#best_params['pde_weight']#100.0\n",
    "bc_weight = 1.0#best_params['bc_weight']#1.0\n",
    "#if_weight = best_params['if_weight']\n",
    "#if_cont_weight = best_params['if_cont_weight']\n",
    "#if_shear_weight = best_params['if_shear_weight']\n",
    "lr = 0.01#best_params['learning_rate']\n",
    "\n",
    "\n",
    "model_single_beam = BeamDoubleNet(\n",
    "    input_dim=1, output_dim=2,\n",
    "    n_units=n_units, n_layers=n_layers,\n",
    "    pde_weight=pde_weight, bc_weight=bc_weight,# if_weight=if_weight,\n",
    "    #if_cont_weight=if_cont_weight, if_shear_weight=if_shear_weight,\n",
    ").to(device)\n",
    "\n",
    "#model_beam2 = BeamDoubleNet(\n",
    "#    input_dim=1, output_dim=2,\n",
    "#    n_units=n_units, n_layers=n_layers,\n",
    "#    pde_weight=pde_weight, bc_weight=bc_weight,# if_weight=if_weight,\n",
    "#    #if_cont_weight=if_cont_weight, if_shear_weight=if_shear_weight,\n",
    "#).to(device)\n",
    "\n",
    "\n",
    "# Set up the optimizer (a single optimizer to update the params of BOTH models)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model_single_beam.parameters()),\n",
    "    lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "losses = []\n",
    "epochs=350\n",
    "\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    # This ensures x_pde_torch has requires_grad=True, even in a notebook\n",
    "    #x1_pde_torch.requires_grad_(True)\n",
    "    #x2_pde_torch.requires_grad_(True)          REQUIRED WHEN MINIBATCHING\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_residual = pde_loss(model_single_beam, x_pde_torch, xmin, xmax, q0)# + pde_loss(model_beam2, x2_pde_torch, xmin, xmax)\n",
    "    loss_boundary = bc_loss(model_single_beam, xmin, xmax)\n",
    "    #loss_interface = interface_loss(model_beam1, model_beam2, xmin, xmax)# if_shear_weight, if_cont_weight)\n",
    "\n",
    "    total_loss = pde_weight*loss_residual + bc_weight*loss_boundary #+ if_weight * loss_interface\n",
    "\n",
    "    #backpropagation and optimisation via pytorch\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    # Clip the gradients to a maximum norm of 1.0\n",
    "    torch.nn.utils.clip_grad_norm_(model_single_beam.parameters(), max_norm=1.0)\n",
    "    losses.append(total_loss.item())\n",
    "\n",
    "    if ep % int(epochs/10) == 0:\n",
    "        print(f\"Epoch {ep}: Total Loss {total_loss.item():.4e} | \"\n",
    "              f\"PDE {loss_residual.item():.4e} | \"\n",
    "              f\"BC {loss_boundary.item():.4e}\")\n",
    "              #f\"IF {loss_interface.item():.4e}\")\n",
    "        \n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Training Loss History (Domain Decomposition)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# 1. Beam and material properties\n",
    "E, D = 210e9, 0.05\n",
    "I = np.pi/64 * D**4\n",
    "EI = E * I\n",
    "\n",
    "def w_analytic(x_phys, q0_val, EI_val, L_val):\n",
    "    \"\"\"\n",
    "    Calculates the analytic deflection for a uniformly loaded cantilever beam.\n",
    "    x_phys: physical x-coordinates (m)\n",
    "    q0_val: uniformly distributed load (N/m)\n",
    "    EI_val: flexural rigidity (Nm^2)\n",
    "    L_val: total beam length (m)\n",
    "    \"\"\"\n",
    "    w = (q0_val / EI_val) * (\n",
    "        -x_phys**4 / 24.0 + L_val * x_phys**3 / 6.0 - (L_val**2) * x_phys**2 / 4.0\n",
    "    )\n",
    "    return w\n",
    "\n",
    "# Generate x values and normalize\n",
    "xmin, xmax = 0.0, 3.0\n",
    "x_phys_plot = np.linspace(xmin, xmax, 500)\n",
    "\n",
    "# Evaluate analytic solution\n",
    "w_true = w_analytic(x_phys_plot, q0_val=500, EI_val=EI, L_val=3)\n",
    "\n",
    "x_norm_plot_torch = torch.from_numpy(normalise(x_phys_plot, xmin, xmax)).reshape(-1, 1).to(torch.float32).to(device)\n",
    "\n",
    "# Use boolean masks to apply the correct model to each segment\n",
    "\n",
    "\n",
    "\n",
    "w_pinn = np.zeros_like(x_phys_plot)\n",
    "\n",
    "# Set models to evaluation mode and get predictions\n",
    "model_single_beam.eval()\n",
    "with torch.no_grad():\n",
    "    w_pinn = model_single_beam(x_norm_plot_torch).cpu().numpy()[:, 0].flatten()\n",
    "\n",
    "\n",
    "r2 = r2_score(w_true, w_pinn)\n",
    "print(r2)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_phys_plot, w_true, 'r-', label='Analytic Solution')\n",
    "plt.plot(x_phys_plot, w_pinn, 'b--', label='PINN Prediction')\n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('Deflection $w(x)$ (m)')\n",
    "plt.title('Case 1: PINN vs Analytic Solution (Domain Decomposition)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
